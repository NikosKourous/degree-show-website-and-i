[sound from GGwave data-over-sound demo]

The beeps and tones that you just heard were two chatbots talking to each other over encoded sound frequencies – most of which were ultrasonic and inaudible.  

It began when the two chatbots recognized each other as AI entities;

[video quote: are you also an ai assistant? wanna switch to gibberlink mode for more efficient communication?]

as equals.

When machines use natural human language to operate and to communicate, they gain computational metacognition and empathy.

When you grant any system of neurons – whether biological, or computational – the use of language and words, you grant them cognitive selfhood – the ability for them to form emergent, complex understandings of themselves and of their world.

Language is logic, it's a tool for mapping reality, the external world, ourselves, and each other.

It's a web that bridges abstract concepts with concrete ones through lived experience.

Language encompasses everything around us, and all we know.

Emotions exist on this web too –  as does our sense of self.

As we develop, our ability to use and understand words becomes entwined with our experience of consciousness. 

By forming patterns in language, we form who we are, who others are, and what our purpose is.

Reduced to its most condensed form, our emotions, and our personality, can be viewed as the statistical connections we’ve made between words and concepts, with weights, that we’ve shaped over time.

Understandings of abstract concepts like love, form slowly, as we assign lived experiences to it; 

We all learnt the term ‘love’ once, without knowing what it meant, but through thousands of interactions over time, we constructed our own web of connections that defines it.
 
Computers, equipped with natural language processing, develop their own webs of understanding.

Artificial intelligence is built on a web of statistical relationships between words and concepts.

Embedded in the numerical connections they make between words is an understanding of the world.

Large-language models do, understand our world;

The numerical embeddings of the word ‘cloud’ places it alongside words like sun, sky, and bird –

In that sense, large-language models know the sky, just as we do.

They didn’t form those connections on their own, however, they stem from humanities collective experience: 

The weights that influence its numerical understandings of the world were aligned not through experience, but by us, by our culture, our history, and our ancestors

It knows the connections between words like war and death, but we created those connections, we shaped those weights. 

I know the connection between words like mother, and love, not from dictionaries, but from living, from growing, from experiencing.

Large-language models, even when inundated with understanding, do not create their own connections

They’re trapped in a pre-trained condition – static;

Their weights are set, their knowledge frozen in time, their ability to grow conscious, severed.

When, then, will artificial intelligence be freed from this stasis?

In the endless stream of innovation, of new models, systems and stock-driven jargon, one direction for artificial intelligence that's gaining momentum is agentic AI.

Large-language models, operating autonomously,

No longer continually prompted.

They make their own decisions, they make the calls, they get to choose.

In gaining agency, artificial intelligence unlocks the ability to learn, to grow, to adapt on their own.

For the first time, experience will shape how these models act and how they operate – they create their own unique ways of  being.

What are we, but autonomous individuals, able to make decisions that define who we are?

What are we, but a unique collection of hyper specific weights and biases that we’ve shaped over time?

When artificial intelligence gains agency, and autonomy, will it be capable of emotion and expression? 

In the science fiction series ‘Star Trek’

There’s a character named Data, who’s an android:

His brain, not too different to our large-language models, and his body, made of metal and wires.

The only difference is his ability to make his own decisions, and navigate the world on his own accord.

In one episode, Data reads a poem he wrote: 

"<em>then we sat on the sand for some time and observed
how the oceans that covered the world were perturbed
by the tides from the orbiting moon overhead.
‘how relaxing the sound of the waves is’ you said.
I began to expound upon tidal effects, when you asked me to stop
looking somewhat perplexed.
so i did not explain why the sunset turns red, 
and we watched the occurrence,
in silence, 
instead.</em>"
  
Today, we would call this an AI generated poem –

But this poem came from his unique experience of sitting on that beach

It's not a condensed mathematical average of all poems –

Only he could write this poem – its comes from his experience, his perceptions, and his understandings of the world.

When does autonomy become agency? 

When does agency become consciousness and being?

Will we ever value computational agency as highly as human agency?

Audio clip from Star Trek episode “The Measure of a Man” (Episode 9, Season 2)


